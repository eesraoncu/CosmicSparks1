# AkÄ±llÄ± Pipeline Sistemi - KullanÄ±m KÄ±lavuzu

## ğŸ¯ Genel BakÄ±ÅŸ

Bu sistem, TÃ¼rkiye'nin **81 ili iÃ§in otomatik olarak** en gÃ¼ncel veri kaynaÄŸÄ±nÄ± bulur ve eksik verileri akÄ±llÄ±ca doldurur. Sistem:

1. âœ… Her il iÃ§in **ayrÄ± ayrÄ±** en yakÄ±n gerÃ§ek veriyi bulur
2. âœ… GerÃ§ek veri mevcutsa **pipeline'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r** (MODIS, CAMS, ERA5)
3. âœ… GerÃ§ek veri yoksa **tahmin algoritmasÄ±** ile 3 ay geriye giderek veri Ã¼retir
4. âœ… TÃ¼m sonuÃ§larÄ± **otomatik olarak veritabanÄ±na** kaydeder

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Basit KullanÄ±m (Ã–nerilen)

TÃ¼m illeri analiz et ve eksik verileri doldur:

```bash
python run_intelligent_pipeline.py
```

Bu komut:
- Son 90 gÃ¼n iÃ§indeki verileri kontrol eder
- 7 gÃ¼nden eski verileri "gÃ¼ncel deÄŸil" olarak kabul eder
- Eksik tarihleri bulur ve doldurur
- SonuÃ§larÄ± veritabanÄ±na kaydeder

### 2. Sadece Analiz (Veri Ä°ÅŸlemeden)

Mevcut veri durumunu kontrol et:

```bash
python run_intelligent_pipeline.py --analyze-only
```

Ã‡Ä±ktÄ± Ã¶rneÄŸi:
```
================================================================================
DATA COVERAGE ANALYSIS
================================================================================
Total provinces: 81
Provinces with data: 65 (80.2%)
Provinces without data: 16
Provinces needing update: 32
Total missing records: 1,458
Oldest data: 2024-07-15
Newest data: 2024-10-03
================================================================================
```

### 3. Ã–zelleÅŸtirilmiÅŸ Parametreler

```bash
# 30 gÃ¼n geriye git (3 ay yerine)
python run_intelligent_pipeline.py --max-lookback 30

# 3 gÃ¼nden eski veriyi "eski" say (7 gÃ¼n yerine)
python run_intelligent_pipeline.py --min-age 3

# DetaylÄ± log kayÄ±tlarÄ±
python run_intelligent_pipeline.py --verbose

# SonuÃ§larÄ± JSON dosyasÄ±na kaydet
python run_intelligent_pipeline.py --export-report report.json
```

## ğŸ“Š API KullanÄ±mÄ±

### REST API Endpoint'leri

#### 1. Pipeline'Ä± Ã‡alÄ±ÅŸtÄ±r

```http
POST /api/pipeline/run-intelligent?max_lookback_days=90&min_data_age_days=7
```

YanÄ±t:
```json
{
  "status": "success",
  "summary": {
    "initial_coverage_pct": 65.4,
    "final_coverage_pct": 98.8,
    "dates_processed_with_real_data": 12,
    "forecast_records_generated": 845,
    "total_records_added": 1817,
    "provinces_updated": 80
  }
}
```

#### 2. Sadece Analiz

```http
POST /api/pipeline/run-intelligent?analyze_only=true
```

#### 3. DetaylÄ± Kapsama Analizi

```http
GET /api/pipeline/coverage-analysis?max_lookback_days=90
```

YanÄ±t:
```json
{
  "analysis": {
    "total_provinces": 81,
    "provinces_with_data": 65,
    "coverage_pct": 80.2
  },
  "provinces": {
    "1": {
      "name": "Adana",
      "latest_date": "2024-10-01",
      "days_old": 3,
      "has_recent_data": true
    },
    "6": {
      "name": "Ankara",
      "latest_date": "2024-09-15",
      "days_old": 19,
      "has_recent_data": false
    }
  }
}
```

## ğŸ”§ Sistem NasÄ±l Ã‡alÄ±ÅŸÄ±r?

### AdÄ±m 1: Veri Durumu Analizi

Sistem her il iÃ§in ayrÄ± ayrÄ± kontrol yapar:

```
Ä°l: Ankara
â”œâ”€ Son gerÃ§ek veri: 2024-09-20 (14 gÃ¼n Ã¶nce)
â”œâ”€ Durum: GÃ¼ncel deÄŸil (>7 gÃ¼n)
â””â”€ Aksiyon: 2024-09-21'den bugÃ¼ne kadar doldur
```

### AdÄ±m 2: GerÃ§ek Veri Pipeline'Ä±

EÄŸer ham veri mevcutsa (MODIS, CAMS, ERA5):

```python
# Otomatik olarak Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r:
orchestrate_day("2024-10-01")
```

Bu iÅŸlem ÅŸunlarÄ± yapar:
1. âœ… MODIS AOD verilerini iÅŸler
2. âœ… CAMS toz verilerini iÅŸler
3. âœ… ERA5 meteorolojik verilerini iÅŸler
4. âœ… Ä°l bazÄ±nda istatistik hesaplar
5. âœ… PM2.5 tahmini yapar
6. âœ… VeritabanÄ±na kaydeder

### AdÄ±m 3: Tahmin Sistemi

EÄŸer gerÃ§ek veri yoksa:

```python
# Her il iÃ§in tahmin Ã¼retir
prediction = forecast_system.predict_pm25(province_id, date)
```

Tahmin ÅŸunlarÄ± iÃ§erir:
- PM2.5 konsantrasyonu (Î¼g/mÂ³)
- GÃ¼ven aralÄ±klarÄ± (alt/Ã¼st)
- AOD deÄŸerleri
- Toz olayÄ± tespiti
- Hava kalitesi kategorisi
- Belirsizlik metrikleri

### AdÄ±m 4: VeritabanÄ±na KayÄ±t

TÃ¼m veriler `daily_stats` tablosuna kaydedilir:

```sql
INSERT INTO daily_stats (
  date, province_id, pm25, aod_mean, dust_event_detected,
  air_quality_category, data_quality_score, ...
) VALUES (...);
```

## ğŸ“ˆ Veri Kalite GÃ¶stergeleri

Sistemde 2 tÃ¼r veri vardÄ±r:

### 1. GerÃ§ek Veri
```json
{
  "data_quality_score": 0.95,
  "source": "MODIS + CAMS + ERA5",
  "pm25": 35.2,
  "pm25_uncertainty": 5.1
}
```

### 2. Tahmin Verisi
```json
{
  "data_quality_score": 0.7,
  "source": "Forecast Model",
  "pm25": 28.5,
  "pm25_uncertainty": 12.3
}
```

`data_quality_score` deÄŸeri:
- **0.7**: Tahmin verisi
- **0.7 - 1.0**: GerÃ§ek veri (kapsama oranÄ±na gÃ¶re)

## ğŸ¯ KullanÄ±m SenaryolarÄ±

### Senaryo 1: GÃ¼nlÃ¼k Otomatik Ã‡alÄ±ÅŸtÄ±rma

Scheduler'a ekle (Ã¶rn: cron):

```bash
# Her gÃ¼n sabah 07:00'de Ã§alÄ±ÅŸtÄ±r
0 7 * * * cd /dust-mvp && python run_intelligent_pipeline.py
```

### Senaryo 2: Ä°lk Veri YÃ¼kleme

Sistemde hiÃ§ veri yoksa:

```bash
# 3 aylÄ±k geÃ§miÅŸi doldur
python run_intelligent_pipeline.py --max-lookback 90
```

### Senaryo 3: Acil GÃ¼ncelleme

Sadece son 7 gÃ¼nÃ¼ kontrol et:

```bash
python run_intelligent_pipeline.py --max-lookback 7 --min-age 1
```

### Senaryo 4: Belirli Bir Tarihi Ä°ÅŸle

Belirli bir gÃ¼n iÃ§in pipeline Ã§alÄ±ÅŸtÄ±r:

```bash
python -m src.orchestrate_day --date 2024-10-01
```

## ğŸ” Sorun Giderme

### Problem: "No real data available"

**Ã‡Ã¶zÃ¼m**: Ham veri dosyalarÄ±nÄ± kontrol edin:

```bash
# MODIS verileri
ls data/raw/modis/20241001/

# CAMS verileri
ls data/raw/cams/cams_dust_analysis_20241001.nc

# ERA5 verileri
ls data/raw/era5/era5_20241001.nc
```

### Problem: "Forecast records not being saved"

**Ã‡Ã¶zÃ¼m**: VeritabanÄ± baÄŸlantÄ±sÄ±nÄ± kontrol edin:

```python
# test_db_connection.py
from src.database import db_manager

with db_manager.get_session() as session:
    print(f"Connection OK: {session.is_active}")
```

### Problem: "Coverage not improving"

**Ã‡Ã¶zÃ¼m**: Verbose log ile Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python run_intelligent_pipeline.py --verbose
```

Log dosyasÄ±nÄ± inceleyin: `intelligent_pipeline.log`

## ğŸ“ Log DosyalarÄ±

Sistem 2 log dosyasÄ± Ã¼retir:

### 1. intelligent_pipeline.log

Pipeline Ã§alÄ±ÅŸma kayÄ±tlarÄ±:
```
2024-10-04 14:23:15 - INFO - Finding latest real data for each province...
2024-10-04 14:23:16 - INFO - Province Ankara (6): Latest data on 2024-09-20
2024-10-04 14:23:17 - INFO - Generating forecasts for 2024-09-21...
```

### 2. scheduler.log

Otomatik Ã§alÄ±ÅŸma kayÄ±tlarÄ± (eÄŸer scheduler kullanÄ±lÄ±yorsa):
```
2024-10-04 07:00:00 - INFO - Starting scheduled pipeline run
2024-10-04 07:35:12 - INFO - Pipeline completed successfully
```

## ğŸŒ Frontend Entegrasyonu

Frontend'den API kullanÄ±mÄ±:

```typescript
// utils/api.ts

export async function runIntelligentPipeline() {
  const response = await fetch('/api/pipeline/run-intelligent', {
    method: 'POST'
  });
  
  return response.json();
}

export async function getCoverageAnalysis() {
  const response = await fetch('/api/pipeline/coverage-analysis');
  return response.json();
}
```

```typescript
// components/AdminPanel.tsx

const handleRunPipeline = async () => {
  setLoading(true);
  
  try {
    const result = await runIntelligentPipeline();
    
    alert(`Pipeline baÅŸarÄ±lÄ±!
      Ä°ÅŸlenen tarihler: ${result.summary.dates_processed_with_real_data}
      Ãœretilen tahminler: ${result.summary.forecast_records_generated}
      Kapsama: ${result.summary.final_coverage_pct.toFixed(1)}%
    `);
  } catch (error) {
    alert('Hata: ' + error.message);
  } finally {
    setLoading(false);
  }
};
```

## ğŸ“Š Performans ve SÄ±nÄ±rlamalar

### Performans Metrikleri

- **Analiz sÃ¼resi**: ~2-5 saniye (81 il)
- **Tahmin Ã¼retimi**: ~0.1 saniye/kayÄ±t
- **GerÃ§ek veri iÅŸleme**: ~30-60 saniye/gÃ¼n
- **Toplam sÃ¼re**: 10-30 dakika (3 aylÄ±k eksik veriler iÃ§in)

### SÄ±nÄ±rlamalar

- **Max lookback**: 365 gÃ¼n (performans nedeniyle)
- **Max forecasts**: 81 il Ã— 90 gÃ¼n = 7,290 kayÄ±t (bir Ã§alÄ±ÅŸtÄ±rmada)
- **API timeout**: 60 dakika (uzun iÅŸlemler iÃ§in)

### Optimizasyon Ä°puÃ§larÄ±

1. **Paralel iÅŸlem**: Worker pool kullanarak tarihleri paralel iÅŸleyin
2. **Batch insert**: VeritabanÄ± kayÄ±tlarÄ±nÄ± toplu ekleyin
3. **Cache**: Son analiz sonuÃ§larÄ±nÄ± cache'leyin
4. **Incremental**: Sadece son 7 gÃ¼nÃ¼ gÃ¼nlÃ¼k olarak gÃ¼ncelleyin

## ğŸ” GÃ¼venlik

### API GÃ¼venliÄŸi

Pipeline endpoint'leri iÃ§in authentication ekleyin:

```python
@app.post("/api/pipeline/run-intelligent")
async def run_intelligent_pipeline(
    current_user: User = Depends(get_current_user)
):
    # Sadece admin kullanÄ±cÄ±lar Ã§alÄ±ÅŸtÄ±rabilir
    if current_user.role != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Pipeline Ã§alÄ±ÅŸtÄ±r...
```

### Rate Limiting

AynÄ± anda birden fazla pipeline Ã§alÄ±ÅŸmasÄ±nÄ± engelleyin:

```python
# Redis veya memory cache kullanarak
if pipeline_is_running():
    raise HTTPException(status_code=429, detail="Pipeline already running")
```

## ğŸ“ Destek ve KatkÄ±

### Sorun Bildirme

1. Log dosyalarÄ±nÄ± toplayÄ±n
2. Hata mesajÄ±nÄ± kopyalayÄ±n
3. KullanÄ±lan komut ve parametreleri belirtin
4. GitHub issue oluÅŸturun

### KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun
3. Test edin
4. Pull request gÃ¶nderin

## ğŸ“š Ä°lgili Dosyalar

- `src/intelligent_pipeline_orchestrator.py` - Ana orchestrator sÄ±nÄ±fÄ±
- `src/forecast_system.py` - Tahmin algoritmalarÄ±
- `src/orchestrate_day.py` - GÃ¼nlÃ¼k pipeline
- `src/api.py` - REST API endpoints
- `run_intelligent_pipeline.py` - CLI arayÃ¼zÃ¼

## âœ… Kontrol Listesi

Pipeline Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce:

- [ ] VeritabanÄ± Ã§alÄ±ÅŸÄ±yor mu?
- [ ] `config/params.yaml` ayarlarÄ± doÄŸru mu?
- [ ] Ham veri dizinleri mevcut mu?
- [ ] Disk alanÄ± yeterli mi? (en az 5GB)
- [ ] API anahtarlarÄ± geÃ§erli mi? (CAMS, MODIS)

---

**Version**: 1.0.0  
**Son GÃ¼ncelleme**: 2024-10-04  
**Lisans**: MIT

